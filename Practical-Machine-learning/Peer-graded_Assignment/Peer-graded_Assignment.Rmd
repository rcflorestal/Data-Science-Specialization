---
title: "Human Activity Recognition"
author: "Robson Cruz"
date: "12/05/2021"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
Human Activity Recognition (HAR) has emerged as a key research area in the last
years and is gaining increasing attention by the pervasive computing research 
community (see picture below, that illustrates the increasing number of publications 
in HAR with wearable accelerometers), especially for the development of context-aware 
systems. There are many potential applications for HAR, like: elderly monitoring, 
life log systems for monitoring energy expenditure and for supporting weight-loss 
programs, and digital assistants for weight lifting exercises.
According to [1] it is possible to detect mistakes by classification in HAR data
set. Customized application of this dataset can be seen in [2].
The goal of this project is to predict the manner in which the subjects exercised. 

## Metodology
In this project we made use of the Human Activity Recognition dataset [3] and 
select the following variables: classe, accel_belt_x, accel_belt_y, accel_belt_z, 
accel_forearm_x, accel_forearm_y, accel_forearm_z, accel_arm_x, accel_arm_y, 
accel_arm_z, accel_dumbbell_x, accel_dumbbell_y and accel_dumbbell_z, which are
collected in six subjects. We use the R program language [4] to run the statistics 
analyze. 
The original dataset was divided in two other data sets, one for validation 
and the other to training. We use the Random Forest algorithm to prediction
because it is usually one of the two top performing algorithms along with
boosting in prediction contests.

## Load packages and Set the work directory
```{r echo = FALSE, message=FALSE, warning=FALSE, comment=''}
## Load packages
library(caret)
library(kernlab)
library(FactoMineR)
library(randomForest)
library(ggplot2)
library(dplyr)
library(tidyr)
library(kableExtra)
## Set the work directory
setwd('C:/Data-Science-Foundations-using-R-Specialization/Practical-Machine-learning/Peer-graded_Assignment/')
```


## Load the data set
```{r import-data, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE, comment='' }
training <- read.csv('./pml-training.csv')

testing <- read.csv('./pml-testing.csv')
```

## Processing Data Set and Results
```{r echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE, comment=''}
## Elimination of Variables
espl <- with(training, split(num_window, f = classe))
for ( i in 1:4 ) {
  for ( j in (i+1):5) {
    set1 <- paste0("(window numbers for activity ", LETTERS[i],")")
    set2 <- paste0("(window numbers for activity ", LETTERS[j],")")
    result <- ifelse(length(intersect(espl[[i]], espl[[j]])) == 0, "empty", "nonempty")
    cat(paste0(set1, " intersect ", set2, " is ", result,"\n"))
  }
}

results_test <- sapply(testing, FUN = function(x) !all(is.na(x)))
goodNames <- names(results_test[results_test])
keepNames <- goodNames[-c(1, 3, 4, 5, 6, 7, 60)]
training2 <- training[, keepNames]

## Convert user_name and classe variables to factors
training2$user_name <- factor(training2$user_name)
training2$classe <- factor(training$classe)

## Split the data set into a 60% training and 40% probing data set
set.seed(32031)
inTrain <- createDataPartition(
        y = training2$classe, p = 0.6, list = FALSE
)

trainingSample <- training2[inTrain, ] 

## Set the validation data set
test <- training2[-inTrain, ]

## Subset the 'training' data set
test <- test %>% select(
        user_name, classe, 
        accel_belt_x, accel_belt_y, accel_belt_z,
        accel_forearm_x, accel_forearm_y, accel_forearm_z,
        accel_arm_x, accel_arm_y, accel_arm_z,
        accel_dumbbell_x, accel_dumbbell_y, accel_dumbbell_z
)
test$classe <- factor(test$classe)
test$user_name <- factor(test$user_name)

trainingSample <- trainingSample %>% select(
        user_name, classe, 
        accel_belt_x, accel_belt_y, accel_belt_z,
        accel_forearm_x, accel_forearm_y, accel_forearm_z,
        accel_arm_x, accel_arm_y, accel_arm_z,
        accel_dumbbell_x, accel_dumbbell_y, accel_dumbbell_z
)

## Convert user_name and classe variables to factors
trainingSample$classe <- factor(trainingSample$classe)
```

The summary statistics for training data set and test dataset are shown below.
```{r echo = TRUE, cache = TRUE, message=FALSE, warning=FALSE, comment=''}
## Summary statistics
summary(trainingSample)
summary(test)
```

The following _figure_  shows the distribution of the variables evaluated 
according to the classe.

```{r echo = TRUE, cache = TRUE}
## plot variables as function of classe
trainingSample2 <- trainingSample %>%
        tidyr::pivot_longer(
                cols = starts_with('accel'),
                values_to = 'value'
        )

trainingSample2 %>%
        ggplot(aes(x = classe, y = value)) +
        geom_violin(aes(color = classe, fill = classe, alpha = 0.4)) +
        facet_wrap(~ name, scales = 'free_y') +
        scale_color_brewer(palette = 'Spectral') +
        scale_fill_brewer(palette = 'Spectral') +
        stat_summary(fun = mean, geom = 'point', shape = 23, size = 2) +
        geom_boxplot(width = 0.1) +
        labs(x = "", y = "") +
        theme(legend.position = "none")
```

The result of the analysis with the Random forest algorithm is shown below, 
where it is possible to observe that the three most important variables are 
accel_belt_z, accel_dumbbell_y and accel_arm_x.

```{r echo = TRUE, cache = TRUE, message=FALSE, warning=FALSE, comment=''}
#####-> Model Fitting with Random Forest package
set.seed(30131)
rf.prelim <- randomForest(
        x = trainingSample[, -1],
        y = trainingSample$classe,
        #mtry = 2,
        #importance = TRUE,
        do.trace = 50      ## to print every fifty trees
)

rf.prelim

set.seed(1113)
rf = train(
        x = trainingSample[, -c(1, 2)],
        y = trainingSample$classe,
        method = 'rf',
        trControl = trainControl(method = 'oob'),
        allowParallel = TRUE,
        ntree = 300,
        importance = TRUE,
        tuneLength = 10
)

rf

## Compare Predictions with Validation Set
preds <- predict(rf, newdata = trainingSample)
confusionMatrix(preds, trainingSample$classe)

## Show up the most important variable
rf_plot <- varImp(rf, scale = FALSE, type = 1)
plot(
        rf_plot, top = 10, main = 'Variable-Importance Plot',
        xlab = 'Importance (Mean Decrease in Accuracy)'
)

## Final Test
test2 <- testing[, keepNames]
test2$user_name <- factor(test2$user_name)

examPreds <- predict(rf, newdata = test2)
results <- matrix(examPreds, nrow = 1)
colnames(results) <- test$problem_id
kable(results)

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("answers/problem_id_", i, ".txt")
    write.table(x[i], 
                file = filename,
                quote = FALSE, 
                row.names = FALSE, 
                col.names = FALSE)
  }
}

pml_write_files(examPreds)
```

## REFERENCES
[1] Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative
Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International
Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, 
Germany: ACM SIGCHI, 2013.

[2] Ugulino, W.; Ferreira, M.; Velloso, E.; Fuks, H. Virtual Caregiver:
Colaboração de Parentes no Acompanhamento de Idosos. Anais do SBSC 2012, 
IX Simpósio Brasileiro de Sistemas Colaborativos , pp. 43-48. São Paulo, 
SP: IEEE, 2012. ISBN 978-0-7695-4890-6.


[3] Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, 
H. Wearable Computing: Accelerometers' Data Classification of Body Postures 
and Movements. Proceedings of 21st Brazilian Symposium on Artificial Intelligence.
Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer 
Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. 
ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6.


[4] R Core Team (2020). R: A language and environment for statistical computing. 
R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.




